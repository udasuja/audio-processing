{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "음성합성을 위한 데이터셋"
      ],
      "metadata": {
        "id": "t63izR8RUEqF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_gvlNFQCM8W",
        "outputId": "6da14fdf-0f18-48ce-cc7e-f21b64b5c23a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q librosa soundfile\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import os\n",
        "import time\n",
        "import csv\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from base64 import b64decode\n",
        "from google.colab.output import eval_js\n",
        "from IPython.display import display, HTML, Audio\n",
        "\n",
        "# ─── 1. Tacotron 학습용 대본 리스트 ────────────────────────────────────────────\n",
        "scripts = [\n",
        "    \"안녕하세요, 오늘 날씨는 맑고 화창합니다.\",\n",
        "    \"서울에서 부산까지 KTX로 두 시간이 걸립니다.\",\n",
        "    \"집 앞 공원에서 아이들이 공놀이를 하고 있습니다.\",\n",
        "    \"다음 주 금요일 오후 세 시에 회의가 잡혀 있습니다.\",\n",
        "    \"한국의 전통 음식 중 하나인 비빔밥은 맛과 영양이 뛰어납니다.\",\n",
        "    \"컴퓨터 비전과 자연어 처리는 인공지능의 주요 분야입니다.\",\n",
        "    \"오늘 아침에 마신 커피 한 잔이 정신을 맑게 해 주었습니다.\",\n",
        "    \"자동차를 운전할 때는 항상 안전벨트를 착용해야 합니다.\",\n",
        "    \"프로그래밍 언어 파이썬은 배우기 쉽고 강력합니다.\",\n",
        "    \"바닷가에서 들려오는 파도 소리는 마음을 편안하게 해 줍니다.\"\n",
        "]\n",
        "\n",
        "# ─── 2. 녹음 파일 저장 디렉터리 및 메타 리스트 ───────────────────────────────\n",
        "os.makedirs(\"recordings\", exist_ok=True)\n",
        "metadata = []  # (wav_path, transcript) 튜플을 저장할 리스트\n",
        "\n",
        "# ─── 3. 녹음 및 WAV 변환 함수 ─────────────────────────────────────────────────\n",
        "def record_script(text, filename, duration=7):\n",
        "    # 화면에 대본 표시\n",
        "    display(HTML(f\"<h3>다음 문장을 따라 읽어주세요:</h3>\"\n",
        "                 f\"<p style='font-size:20px;'>{text}</p>\"))\n",
        "\n",
        "    # JS로 녹음 및 카운트다운 UI 실행 (async IIFE로 감싸기)\n",
        "    js = f\"\"\"\n",
        "(async () => {{\n",
        "  const duration = {duration};\n",
        "  const timerDiv = document.createElement('div');\n",
        "  timerDiv.id = 'countdown';\n",
        "  timerDiv.style.fontSize = '20px';\n",
        "  timerDiv.style.marginBottom = '10px';\n",
        "  document.body.appendChild(timerDiv);\n",
        "\n",
        "  const stream = await navigator.mediaDevices.getUserMedia({{ audio: true }});\n",
        "  const recorder = new MediaRecorder(stream);\n",
        "  const chunks = [];\n",
        "  recorder.ondataavailable = e => chunks.push(e.data);\n",
        "  recorder.start();\n",
        "\n",
        "  for (let i = duration; i >= 0; i--) {{\n",
        "    timerDiv.innerText = `녹음 중: ${{i}}초 남음`;\n",
        "    await new Promise(r => setTimeout(r, 1000));\n",
        "  }}\n",
        "\n",
        "  recorder.stop();\n",
        "  await new Promise(r => recorder.onstop = r);\n",
        "  timerDiv.innerText = '녹음 완료!';\n",
        "\n",
        "  const blob = new Blob(chunks);\n",
        "  const reader = new FileReader();\n",
        "  reader.readAsDataURL(blob);\n",
        "  await new Promise(r => reader.onloadend = r);\n",
        "  timerDiv.remove();\n",
        "  return reader.result.split(',')[1];\n",
        "}})();\n",
        "    \"\"\"\n",
        "    b64data = eval_js(js)\n",
        "    audio_bytes = b64decode(b64data)\n",
        "\n",
        "    # WEBM 파일로 임시 저장\n",
        "    path_webm = os.path.join(\"recordings\", filename + \".webm\")\n",
        "    with open(path_webm, \"wb\") as f:\n",
        "        f.write(audio_bytes)\n",
        "\n",
        "    # librosa로 로드 후 soundfile로 WAV 저장 (16-bit PCM)\n",
        "    audio, sr = librosa.load(path_webm, sr=441000) #sampling rate 44.1kHz으로 설정\n",
        "    path_wav = os.path.join(\"recordings\", filename + \".wav\")\n",
        "    sf.write(path_wav, audio, sr, subtype='PCM_16')\n",
        "\n",
        "    # 임시 WEBM 파일 삭제\n",
        "    os.remove(path_webm)\n",
        "\n",
        "    print(f\"저장 완료 (WAV): {path_wav}\")\n",
        "    # 녹음된 WAV 재생\n",
        "    display(Audio(path_wav, autoplay=False))\n",
        "    return path_wav\n",
        "\n",
        "# ─── 4. 대본별 순차 녹음 진행 ──────────────────────────────────────────────────\n",
        "for idx, text in enumerate(scripts, start=1):\n",
        "    fname = f\"utt_{idx:02d}\"\n",
        "    wav_path = record_script(text, fname, duration=7)\n",
        "    metadata.append((wav_path, text))\n",
        "    time.sleep(1)\n",
        "\n",
        "# ─── 5. CSV로 대본 메타데이터 저장 ─────────────────────────────────────────────\n",
        "csv_path = os.path.join(\"recordings\", \"transcripts.csv\")\n",
        "with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"filename\", \"transcript\"])\n",
        "    for wav_path, transcript in metadata:\n",
        "        writer.writerow([os.path.basename(wav_path), transcript])\n",
        "\n",
        "print(f\"\\n모든 녹음 완료! 대본 CSV 저장: {csv_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# /content/recordings 디렉터리 생성 (기존 삭제 후)\n",
        "!rm -rf /content/recordings\n",
        "!mkdir -p /content/recordings\n",
        "\n",
        "# recordings.zip 내용 /content/recordings 에 풀기\n",
        "!unzip -o recordings.zip -d /content/recordings\n",
        "\n",
        "# 결과 확인\n",
        "!ls /content/recordings"
      ],
      "metadata": {
        "id": "vjlOOgOBgVNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VITS 기반 음성합성 학습 및 생성"
      ],
      "metadata": {
        "id": "4hGFzR_OdokZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json # JSON 파일 수정을 위해 추가\n",
        "\n",
        "# --- 1. VITS GitHub 저장소 클론 및 작업 디렉토리 설정 ---\n",
        "print(\"--- 1. VITS GitHub 저장소 클론 및 작업 디렉토리 설정 ---\")\n",
        "vits_repo_path = \"/content/vits\"\n",
        "if not os.path.exists(vits_repo_path):\n",
        "    print(f\"Cloning VITS repository to {vits_repo_path}...\")\n",
        "    !git clone https://github.com/jaywalnut310/vits.git {vits_repo_path}\n",
        "else:\n",
        "    print(f\"VITS repository already exists at {vits_repo_path}.\")\n",
        "\n",
        "# VITS 디렉토리로 이동 (모든 작업의 기준)\n",
        "%cd {vits_repo_path}\n",
        "print(f\"Current working directory: {os.getcwd()}\")\n",
        "\n",
        "\n",
        "# --- 2. 필수 라이브러리 설치 (★requirements.txt 문제 우회를 위해 수정됨★) ---\n",
        "print(\"\\n--- 2. 필수 라이브러리 설치 ---\")\n",
        "try:\n",
        "    print(\"Installing common dependencies manually to bypass requirements.txt issues...\")\n",
        "    # PyTorch 설치 (GPU 사용 시, Colab 기본 CUDA 11.8)\n",
        "    # CPU 사용 시: !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
        "    !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "    # 파일 목록 생성 스크립트에서 사용:\n",
        "    !pip install pandas scikit-learn\n",
        "\n",
        "    # 오디오 처리 및 유틸리티 (numpy, matplotlib 버전 고정 제거하여 최신 호환 버전 설치 시도)\n",
        "    !pip install librosa soundfile matplotlib scipy numpy einops tensorboardX\n",
        "\n",
        "    # 텍스트 전처리 (한국어 cleaners에 필요):\n",
        "    !pip install text_normalization phonemizer Unidecode # Unidecode 패키지가 unidecode 모듈을 포함합니다.\n",
        "\n",
        "    print(\"Dependency installation completed successfully.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error during dependency installation: {e}\")\n",
        "    print(\"Please check the error and ensure all required packages are installed.\")\n",
        "    # 중요한 오류이므로 여기서 스크립트 실행을 중단할 수 있도록 raise\n",
        "    raise RuntimeError(\"Failed to install all necessary dependencies.\")\n",
        "\n",
        "\n",
        "# --- 3. 코랩 런타임 재시작 (★새로운 라이브러리 적용을 위해 필수★) ---\n",
        "# 이 셀에서 런타임이 재시작되므로, 이후의 모든 코드는 재시작 후에 새로 실행됩니다.\n",
        "# 따라서 이 셀을 실행한 후에는 다시 스크립트의 맨 위부터 실행해야 합니다.\n",
        "print(\"\\n--- 3. 런타임 재시작 중... (필수) ---\")\n",
        "print(\"이 메시지 다음에 런타임이 재시작됩니다. 재시작 후 스크립트를 처음부터 다시 실행해주세요.\")\n",
        "os.kill(os.getpid(), 9) # 런타임 강제 종료 (코랩 재시작과 동일 효과)\n",
        "\n",
        "\n",
        "# --- 4. 데이터셋 파일 목록 생성 (런타임 재시작 후 이어서 실행) ---\n",
        "# (이 부분은 런타임 재시작 후 다시 실행됩니다)\n",
        "print(\"\\n--- 4. 데이터셋 파일 목록 생성 ---\")\n",
        "transcripts_file_path = '/content/recordings/transcripts.csv' # 사용자 데이터셋 transcripts.csv 경로\n",
        "audio_root_path = '/content/recordings/' # 사용자 데이터셋 .wav 파일들이 있는 폴더\n",
        "\n",
        "output_filelist_dir = './filelists'\n",
        "os.makedirs(output_filelist_dir, exist_ok=True)\n",
        "\n",
        "if os.path.exists(transcripts_file_path):\n",
        "    print(f\"Reading transcripts from {transcripts_file_path}...\")\n",
        "    df = pd.read_csv(transcripts_file_path, sep=',', header=0)\n",
        "    df['filename'] = df['filename'].apply(lambda x: os.path.join(audio_root_path, x))\n",
        "\n",
        "    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "    train_filelist_path = os.path.join(output_filelist_dir, 'train_filelist.txt')\n",
        "    val_filelist_path = os.path.join(output_filelist_dir, 'val_filelist.txt')\n",
        "\n",
        "    train_df[['filename', 'transcript']].to_csv(train_filelist_path, sep='|', index=False, header=False, encoding='utf-8')\n",
        "    val_df[['filename', 'transcript']].to_csv(val_filelist_path, sep='|', index=False, header=False, encoding='utf-8')\n",
        "\n",
        "    print(f\"Train file list created: {train_filelist_path}\")\n",
        "    print(f\"Validation file list created: {val_filelist_path}\")\n",
        "\n",
        "    # 파일 내용 일부 확인\n",
        "    print(\"\\n--- train_filelist.txt sample content ---\")\n",
        "    with open(train_filelist_path, 'r', encoding='utf-8') as f:\n",
        "        for i, line in enumerate(f):\n",
        "            print(line.strip())\n",
        "            if i >= 2: break\n",
        "else:\n",
        "    print(f\"Error: transcripts.csv not found at {transcripts_file_path}. Please upload your dataset.\")\n",
        "    raise FileNotFoundError(f\"transcripts.csv not found at {transcripts_file_path}\")\n",
        "\n",
        "\n",
        "# --- 5. VITS 설정 파일 준비 및 수정 (런타임 재시작 후 이어서 실행) ---\n",
        "print(\"\\n--- 5. VITS 설정 파일 준비 및 수정 ---\")\n",
        "config_source_path = 'configs/ljs_base.json' # 기본 설정 파일\n",
        "config_target_path = 'configs/my_korean_vits.json' # 사용자 정의 설정 파일\n",
        "\n",
        "if os.path.exists(config_source_path):\n",
        "    !cp {config_source_path} {config_target_path}\n",
        "    print(f\"Copied {config_source_path} to {config_target_path}\")\n",
        "\n",
        "    # JSON 파일 로드 및 수정\n",
        "    try:\n",
        "        with open(config_target_path, 'r', encoding='utf-8') as f:\n",
        "            config = json.load(f)\n",
        "\n",
        "        # 데이터 관련 설정 수정\n",
        "        config['data']['training_files'] = \"filelists/train_filelist.txt\"\n",
        "        config['data']['validation_files'] = \"filelists/val_filelist.txt\"\n",
        "        config['data']['text_cleaners'] = [\"korean_cleaners\"]\n",
        "        config['data']['sampling_rate'] = 22050 # 사용자 WAV 파일의 실제 샘플링 레이트에 맞춰야 함!\n",
        "        config['data']['n_speakers'] = 0 # 단일 화자\n",
        "\n",
        "        # 모델 관련 설정 수정 (단일 화자이므로 gin_channels 0)\n",
        "        config['model']['gin_channels'] = 0\n",
        "\n",
        "        # 학습 관련 설정 (필요시 batch_size, epochs, fp16_run 등 조절)\n",
        "        config['train']['batch_size'] = 16 # Colab GPU 메모리에 맞춰 조절\n",
        "        config['train']['fp16_run'] = True # GPU 사용 시 True, CPU 사용 시 False\n",
        "\n",
        "        with open(config_target_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(config, f, indent=2, ensure_ascii=False) # 한글 깨짐 방지를 위해 ensure_ascii=False\n",
        "        print(f\"Configuration file {config_target_path} updated successfully.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error updating JSON configuration: {e}\")\n",
        "        print(\"Please check the JSON file manually for correctness.\")\n",
        "else:\n",
        "    print(f\"Error: Source config file {config_source_path} not found. Cannot create custom config.\")\n",
        "\n",
        "\n",
        "# --- 6. (선택 사항) TensorBoard 실행 (런타임 재시작 후 이어서 실행) ---\n",
        "print(\"\\n--- 6. (Optional) TensorBoard 실행 ---\")\n",
        "try:\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir logs/\n",
        "    print(\"TensorBoard started. Check the link above for monitoring.\")\n",
        "except Exception as e:\n",
        "    print(f\"Could not start TensorBoard: {e}. It might be a Colab environment issue.\")\n",
        "\n",
        "\n",
        "# --- 7. VITS 학습 실행 (런타임 재시작 후 이어서 실행) ---\n",
        "print(\"\\n--- 7. VITS 학습 실행 ---\")\n",
        "model_name = \"my_korean_model\" # 학습 로그 및 체크포인트가 저장될 이름\n",
        "config_file = config_target_path # 사용할 설정 파일\n",
        "\n",
        "print(f\"Starting VITS training with config: {config_file}, model name: {model_name}\")\n",
        "!python train.py -c {config_file} -m {model_name}\n",
        "\n",
        "print(\"\\n--- VITS 학습 스크립트 실행 완료 ---\")"
      ],
      "metadata": {
        "id": "Oiq2xAD7dr04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FastSpeech2음성합성 과정"
      ],
      "metadata": {
        "id": "ifXa_npsg0PH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q librosa soundfile g2pk matplotlib"
      ],
      "metadata": {
        "id": "ULnRr1Llgzn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 녹음 전체 코드: 이미 사용자께서 완성한 부분 (생략 가능)\n",
        "# 결과물:\n",
        "# /content/recordings/\n",
        "# ├── utt_01.wav ~ utt_10.wav\n",
        "# └── transcripts.csv"
      ],
      "metadata": {
        "id": "xz7Gj-gTg4Un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 경로 설정\n",
        "wav_path = \"/content/recordings/recordings/utt_01.wav\"\n",
        "\n",
        "# 로드 및 mel 추출\n",
        "# sampling rate를 44.1kHz로 하여 sampling한다. 그리고 fft 한뒤 mel filter bank를 80개로 하여 mel-spectrogram을 생성한다.\n",
        "y, sr = librosa.load(wav_path, sr=44100)\n",
        "mel = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=1024, hop_length=256, n_mels=80)\n",
        "mel_db = librosa.power_to_db(mel, ref=np.max) #mel의 power를 표현하는 값을 log로 표현(dB로 표현)\n",
        "\n",
        "# 시각화\n",
        "plt.figure(figsize=(10, 4))\n",
        "librosa.display.specshow(mel_db, sr=sr, hop_length=256, x_axis=\"time\", y_axis=\"mel\")\n",
        "plt.title(\"녹음 음성의 Mel-Spectrogram\")\n",
        "plt.colorbar(format=\"%+2.0f dB\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bYv_-2n7g6se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from g2pk import G2p\n",
        "\n",
        "g2p = G2p()\n",
        "#text를 사람이 발음하는 음소로 변환한다.\n",
        "text = \"안녕하세요, 오늘 날씨는 맑고 화창합니다.\"\n",
        "phonemes = g2p(text)\n",
        "phoneme_list = phonemes.split()\n",
        "\n",
        "print(\"원문:\", text)\n",
        "print(\"음소:\", phoneme_list)"
      ],
      "metadata": {
        "id": "BDRC-IFNg8IQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R^256차원 내에 token을 embedding한다.\n",
        "embedding_dim = 256\n",
        "embedding_matrix = np.random.randn(len(phoneme_list), embedding_dim)\n",
        "\n",
        "#y축은 음소, x축은 256차원 vector의 각 256개의 cell, 색은 vecotr의 각 cell에 저장된 값\n",
        "plt.figure(figsize=(12, 3))\n",
        "plt.imshow(embedding_matrix, aspect=\"auto\", cmap=\"viridis\")\n",
        "plt.yticks(range(len(phoneme_list)), phoneme_list)\n",
        "plt.colorbar()\n",
        "plt.title(\"Phoneme Embedding 시각화\")\n",
        "plt.xlabel(\"임베딩 차원\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M9zkQ8Hcg9jJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#duration 설정\n",
        "durations = [5] * len(phoneme_list)  # 예시용으로 5프레임씩 할당\n",
        "\n",
        "plt.bar(phoneme_list, durations)\n",
        "plt.title(\"Duration Predictor 출력\")\n",
        "plt.ylabel(\"예측된 프레임 수\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H-3xB-JKg-tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expanded = np.concatenate([\n",
        "    np.tile(embedding_matrix[i], (durations[i], 1))\n",
        "    for i in range(len(phoneme_list))\n",
        "], axis=0)\n",
        "\n",
        "plt.figure(figsize=(12, 3))\n",
        "plt.imshow(expanded, aspect=\"auto\", cmap=\"plasma\")\n",
        "plt.title(\"Length Regulator 출력 (음소 길이 확장)\")\n",
        "plt.xlabel(\"임베딩 차원\")\n",
        "plt.ylabel(\"Time Frames\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ja2GEhs4g_zQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mel_output = np.random.randn(len(expanded), 80)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.imshow(mel_output.T, aspect=\"auto\", origin=\"lower\", cmap=\"magma\")\n",
        "plt.title(\"FastSpeech Decoder 출력 (Mel-Spectrogram 예시)\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Mel bins\")\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "An4FX6WxhDw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mel_output.shape = [T, 80]\n",
        "# vocoder는 각 프레임(T)의 벡터(80차원)를 기반으로 짧은 오디오 조각을 예측하고, 그것들을 이어붙여 wave를 생성함\n",
        "\n",
        "# T개의 프레임을 각각 파형 조각에 매핑한다고 가정하고 그 조각을 이어붙이는 과정 시뮬레이션\n",
        "T = mel_output.shape[0]\n",
        "waveform = np.concatenate([\n",
        "    np.sin(2 * np.pi * np.linspace(0, 1, 200) * (i % 5 + 1)) * (mel_output[i].mean() * 0.1)\n",
        "    for i in range(T)\n",
        "])\n",
        "\n",
        "# 정규화\n",
        "waveform = waveform / np.max(np.abs(waveform))\n",
        "\n",
        "# 시각화\n",
        "plt.figure(figsize=(12, 2))\n",
        "plt.plot(waveform, color=\"blue\")\n",
        "plt.title(\"Vocoder가 만든 가상의 음성 파형\")\n",
        "plt.xlabel(\"샘플 인덱스\")\n",
        "plt.ylabel(\"진폭\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N5NBLspnkpDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "HiFi-GAN Vocoder"
      ],
      "metadata": {
        "id": "CuAaIJDSl88N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "입력: Mel-Spectrogram"
      ],
      "metadata": {
        "id": "qBLFFl6amIJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "\n",
        "T = 100  # time steps\n",
        "mel_dim = 80\n",
        "mel_input = np.random.randn(T, mel_dim)  # 예시 입력\n",
        "\n",
        "plt.figure(figsize=(10, 3))\n",
        "plt.imshow(mel_input.T, aspect=\"auto\", origin=\"lower\", cmap=\"magma\")\n",
        "plt.title(\"① 입력: Mel-Spectrogram\")\n",
        "plt.xlabel(\"Time Frames\")\n",
        "plt.ylabel(\"Mel Bins\")\n",
        "plt.colorbar(label=\"dB\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uTJaw5TLl_xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Upsample: 시간 해상도 증가\n",
        "\n",
        "HiFi-GAN은 ConvTranspose1D(Deconvolution)로 시간축을 늘려 wave에 맞춥니다."
      ],
      "metadata": {
        "id": "wrYVEnDvmFCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sample의 시간 크기를 늘림\n",
        "upsampled_time = T * 8  # 예시로 8배 업샘플링\n",
        "upsampled = np.repeat(mel_input, 8, axis=0)\n",
        "\n",
        "plt.figure(figsize=(10, 2))\n",
        "plt.imshow(upsampled.T, aspect=\"auto\", origin=\"lower\", cmap=\"plasma\")\n",
        "plt.title(\"② Upsample: Mel 시간 해상도 증가\")\n",
        "plt.xlabel(\"Upsampled Time\")\n",
        "plt.ylabel(\"Mel Bins\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4Lncek7SmDYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- MRF: 다양한 필터로 추출 (Multi-Receptive Field)\n",
        "\n",
        "HiFi-GAN은 3가지 다른 커널 크기와 dilation을 가진 Conv 블록을 병렬 적용"
      ],
      "metadata": {
        "id": "94ZvT6lOmLI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MRF 구조 표현용 (세 개의 커널이 병렬로 특징 추출)\n",
        "plt.figure(figsize=(12, 2))\n",
        "for i, k in enumerate([3, 5, 7]):\n",
        "    signal = np.convolve(upsampled[:, 0], np.ones(k)/k, mode='same')\n",
        "    plt.plot(signal, label=f\"커널 {k}\", alpha=0.7)\n",
        "\n",
        "plt.title(\"③ MRF: 다양한 수용 범위 필터 적용\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2IEZlQV9mMkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Residual Blocks: 특징 깊이 있게 변환"
      ],
      "metadata": {
        "id": "AdQsdpVMmP-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.ndimage import gaussian_filter1d\n",
        "\n",
        "# Residual block 결과 시뮬레이션 (부드럽게 만듦)\n",
        "residual_output = gaussian_filter1d(upsampled[:, 0], sigma=3)\n",
        "\n",
        "plt.figure(figsize=(10, 2))\n",
        "plt.plot(residual_output, label=\"Residual Block Output\")\n",
        "plt.title(\"④ Residual Block을 거친 특징 변환\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FbqeTY8mmQbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output: 최종 Waveform 생성"
      ],
      "metadata": {
        "id": "dYSFbHcamS0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예시 파형 출력\n",
        "waveform = residual_output\n",
        "waveform = waveform / np.max(np.abs(waveform))  # 정규화\n",
        "\n",
        "plt.figure(figsize=(12, 2))\n",
        "plt.plot(waveform, color=\"blue\")\n",
        "plt.title(\"⑤ 최종 음성 Waveform (예시)\")\n",
        "plt.xlabel(\"샘플 인덱스\")\n",
        "plt.ylabel(\"진폭\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yIQ2Zis3mUY_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}